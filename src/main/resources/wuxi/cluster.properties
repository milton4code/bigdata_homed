###spark 主节点所对应的域名ip->域名 ###
master_url=spark://172.16.224.170:7077
##master_url=local
###限制spark 集群所能使用的最大cpu核数,建议设置为spark集群机器台数的3倍,如 8个 slave ，则设置 当前值为 24  ###
spark.max.cores=24

##hbase 配置
hbase.zookeeper.property.clientPort=2181
hbase.master.port=16010
hbase.zookeeper.znode.parent=/hbase
#phoenix.ip=192.168.35.107
#phonnix.zkurl=jdbc:phoenix:slave6,slave7,slave8,slave9,slave10:2181
#phonnix.zkurl=jdbc:phoenix:slave1,slave2,slave3:2181
phonnix.zkurl=jdbc:phoenix:172.16.224.171,172.16.224.172,172.16.224.173:2181

###zookeeper集群的服务器地址###
#zookeeper.url=slave6,slave7,slave8,slave9,slave10:2181
zookeeper.url=slave1,slave2,slave3:2181
##默认区域码
region_code=320200

#######################
##日志目录
# hdfs上的arate文件路径
HDFS_ARATE_LOG =/arate/
##ilogslave日志 注意1.0版的是ilogslave
ILOGSLAVE_LOG_PATH=/datamining/ilogslave
#homed2.0 推流日志目录,默认为空,只有当现场部署2.0才填写 /datamining/ilogvss
LOGVSS_LOG_PATH=
##nginx日志目录,day=后面不要加空格
NGINX_JSON_LOG_PATH=/user/hive/warehouse/t_nginx_log_file/day=
#iusm目录 /不能少
IUSM_LOG_PATH=/datamining/iusm/
#iacs /不能少
IACS_LOG_PATH=/datamining/iacs/
#######################

##kafka 集群信息
#kafka.brokers=192.168.18.60:9092,192.168.18.61:9092,192.168.18.63:9092

#post_url
post.url=http://dtv.homed.me/hotkeyword/add
#channel_rank_put_url
#channel_rank_put_url=http://192.168.36.112:13160/habit/put?accesstoken=TOKEN57993853
channel_rank_put_url=http://192.168.35.116:12890/userprofile/channel/put?accesstoken=TOKEN50000060

#orc_video_report  上报日志
#logDF 推流
demand_report=orc_video_report
look_report=orc_video_report
live_report=orc_video_report
timeshift_report=orc_video_report


###
##区域控制开关 0 表示全国项目 1表示省网项目
region_version=1

###终端配置  地方终端找不到 默认配置
#1stb,2 CA卡,3mobile,4 pad, 5pc
terminal =1
###开机报表默认配置
f_phone_model =1
f_app_version =2
f_hard_version =3
f_soft_version =4


###----------------------
##依赖数据源配置
##source 1 用户上报,  2 run日志 , 3 nginx日志 ,4 websocket
##默认1,2,3
log_source=1,2,3

##统计类型全局选项
##1 表示只有机顶盒 2表示移动端(此时需要统计手机,pc,pad这些),3表示机顶盒和移动端都需要统计
##默认1
statistics_type=3
